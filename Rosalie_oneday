import keras
from keras.layers import Input, LSTM, Dense
from keras.models import Model
from keras.models import Sequential
from keras.optimizers import SGD, Adam, RMSprop
import numpy.matlib
from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional
import pandas as pd
import json
from keras.layers import Dense, Activation
import math
from keras.layers import TimeDistributed
import xlrd
import xlsxwriter
from sklearn.utils import class_weight
from sklearn.utils.class_weight import compute_class_weight
import functools
from itertools import product
from sklearn import mixture
import matplotlib.pyplot as plt
from itertools import groupby
from sklearn.metrics import precision_recall_curve
from keras.callbacks import ModelCheckpoint
from sklearn.mixture import GaussianMixture
import numpy as np


#no of clusters = 15
"""
def AB_train(Xtrain,ytrain):
    clf = AdaBoostClassifier(n_estimators=1)
    clf.fit(Xtrain, ytrain)
    return clf


def AB_test(clf, Xtest,ytest):
    ba = clf.predict(Xtest)
    acc = np.abs(ba - ytest)
    acd = 1-(np.count_nonzero(acc)/len(ytest))
    return acd
    
    
def LR_train(Xtrain,ytrain):
    clf = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial').fit(Xtrain, ytrain)
    return clf

def LR_test(clf, Xtest,ytest):
    ba  = clf.predict(Xtest)
    acc = np.abs(ba - ytest)
    print("i am looking ")
    print(acc)
    print(acc.shape)
    acd = 1-(np.count_nonzero(acc)/len(ytest))
    return acd
"""



look_back = 25
num_features = 28
num_class = 4
num_classes = num_class








##########################################################################
data = np.array(pd.read_excel('new_vulture_data.xlsx'))
data = pd.DataFrame(data)
data = data.fillna(method='ffill')
data = np.array(data)

#disney, mac,sarkis,morongo,rosalie
rosalie = data[data[:,13]=='Rosalie']

"""
Xmoon = rosalie[:,21]
Xmoon = Xmoon[0:np.int(0.75*len(Xmoon))]
print(Xmoon)
Xmoon = Xmoon.reshape(-1, 1)
import matplotlib.pyplot as plt
import seaborn as sns; sns.set()
import numpy as np
from sklearn.cluster import KMeans
from scipy.spatial.distance import cdist
from sklearn.mixture import GMM
n_components = np.arange(1, 40)
from sklearn.datasets import make_moons

models = [GMM(n, covariance_type='full', random_state=0).fit(Xmoon)
          for n in n_components]
plt.plot(n_components, [m.bic(Xmoon) for m in models], label='BIC')
plt.plot(n_components, [m.aic(Xmoon) for m in models], label='AIC')
plt.legend(loc='best')
plt.xlabel('n_components');
plt.savefig('1.eps')
plt.show()
"""


rosalie_label = rosalie[:,11]
rosalie_input  = rosalie[:,2:4]
rosalie= rosalie[:,16:]
rosalie_input  =np.hstack((rosalie_input, rosalie))

no = 18
print(len(rosalie_label))
print(len(rosalie_label[no:len(rosalie_label)] ) )
rosalie_label = rosalie_label[no:len(rosalie_label)]
rosalie_input = rosalie_input[0:len(rosalie_input)-no]
print(len(rosalie_input))

"""
ad = sarkis_label.astype(int)
clf =  AB_train(sarkis_input,ad)
acc = AB_test(clf,sarkis_input,ad)
print(acc)
"""

workbook = xlsxwriter.Workbook('rosalie_label.xlsx')
worksheet = workbook.add_worksheet()
row = 0
for col, data in enumerate(rosalie_label.reshape(len(rosalie_label),1).T):
    worksheet.write_column(row, col, data)
workbook.close()


nb_samples = rosalie_input.shape[0] - look_back
Xtrain2 = np.zeros((nb_samples,look_back,num_features))
y_train_reshaped2 = np.zeros((nb_samples,1,num_class))
one_hot_labels2 = np.zeros((nb_samples,1,num_class))
ytra = np.array(pd.get_dummies(np.array(rosalie_label.astype(int).reshape(-1))))
for i in range(nb_samples):
    y_position = i + look_back
    Xtrain2[i] = rosalie_input[i:y_position]
    one_hot_labels2[i] = ytra[y_position,:num_class]
rosalie_input = Xtrain2
rosalie_label = one_hot_labels2










model = Sequential()
opt = Adam(lr=0.001)
model.add(Bidirectional(LSTM(look_back,return_sequences=True), input_shape=(None, num_features) ))
model.add(Bidirectional(LSTM(look_back,return_sequences=True), input_shape=(None, num_features) ))
model.add(Bidirectional(LSTM(look_back,return_sequences=True), input_shape=(None, num_features) ))
model.add(Dropout(0.2))
#model.add(Bidirectional(LSTM(look_back,return_sequences=True), input_shape=(None, num_features) ))


#model.add(SeqSelfAttention(attention_activation = 'sigmoid'))
model.add(TimeDistributed(Dense(num_classes,activation = 'tanh')))
model.add(Activation('softmax'))
model.compile(loss='categorical_crossentropy',
optimizer='adam',
metrics=['categorical_accuracy'])


filepath="weights-improvement1-{epoch:02d}-{val_categorical_accuracy:.2f}.hdf5"
checkpoint = ModelCheckpoint(filepath, monitor='val_categorical_accuracy', verbose=2, save_best_only=True, mode='max')
callbacks_list = [checkpoint]

history = model.fit(rosalie_input, rosalie_label, epochs=50, batch_size=5, verbose=2,validation_split = 0.25,callbacks=callbacks_list)






va = model.predict(rosalie_input)
mali=[]
for j in range(len(va)):
    bc = va[j,:]
    bc = bc[look_back-1,:]
    if j == 0:
        mali = bc
    else:
        mali = np.vstack((mali,bc))



print(mali.shape)
workbook = xlsxwriter.Workbook('rosalie_result_oneday.xlsx')
worksheet = workbook.add_worksheet()
row = 0
for col, data in enumerate(mali.T):
    worksheet.write_column(row, col, data)
workbook.close()
